{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments classification: offensive/non-offensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>یخ علی الخماح مخسر للسیده وجها مازال کتهضرشوهت...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>یاک مطلقها علاش کیحاسبها داب</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>یاخوفي من بدعة التفاخر بالقتل والتشرمیل والمعص...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>يوم يكون الصوت سعره يتحدى 30درهم هنا سيصبح الت...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>يوسف زروالي هو لقتقصدك لدخلو معاه جميعة شباب ا...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  decision\n",
       "0  یخ علی الخماح مخسر للسیده وجها مازال کتهضرشوهت...         1\n",
       "1                       یاک مطلقها علاش کیحاسبها داب         1\n",
       "2  یاخوفي من بدعة التفاخر بالقتل والتشرمیل والمعص...         1\n",
       "3  يوم يكون الصوت سعره يتحدى 30درهم هنا سيصبح الت...         0\n",
       "4  يوسف زروالي هو لقتقصدك لدخلو معاه جميعة شباب ا...         0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Dataset/CVMAD_04.csv', encoding='UTF-8')### if it doesn't work try 'utf-8-sig'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns # visulization\n",
    "sns.countplot(x=df['decision'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def removeWeirdChars(text):\n",
    "    weirdPatterns = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u'\\U00010000-\\U0010ffff'\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\u3030\"\n",
    "                               u\"\\ufe0f\"\n",
    "                               u\"\\u2069\"\n",
    "                               u\"\\u2066\"\n",
    "                               u\"\\u200c\"\n",
    "                               u\"\\u2068\"\n",
    "                               u\"\\u2067\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return weirdPatterns.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.content = [removeWeirdChars(d) for d in df.content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     یخ علی الخماح مخسر للسیده وجها مازال کتهضرشوهت...\n",
       "1                          یاک مطلقها علاش کیحاسبها داب\n",
       "2     یاخوفي من بدعة التفاخر بالقتل والتشرمیل والمعص...\n",
       "3     يوم يكون الصوت سعره يتحدى 30درهم هنا سيصبح الت...\n",
       "4     يوسف زروالي هو لقتقصدك لدخلو معاه جميعة شباب ا...\n",
       "5                                              يوسف رجل\n",
       "6         يوسف الزروالي هو لي دخلو لي جمعية شباب الملكي\n",
       "7                         يوزع شكون فيق سكيزو من السبات\n",
       "8       يوتيب تسبب ليا بمرض نفسي وليت كنخاف ومرضت نفسيا\n",
       "9     يهدر واش تتوقع منو وجاية ملمريخ نتا واش قودك ي...\n",
       "10                                          يهدر كي نسا\n",
       "11    يهدر بحال النسا سبحان الله يا حبيبتي ه و اليد ...\n",
       "12                                   يه الحاجة طامو يه؟\n",
       "13                                       ينقجو و ينحقزو\n",
       "14    ينعل تحية ليك من طانطان هاد شعب فيهم غا هضرة ت...\n",
       "15            ينعل بو زواج الى كان هكا نبقاو بايرات حسن\n",
       "16                    ينصاب يا لقمار يا سكاير طالب سيدك\n",
       "17                        ينتقم للمستقبل ويريد حكم نزيه\n",
       "18       يمهل ولا يهمل غدي تبان فيك اولدي عقل على كلمتي\n",
       "19                 يمهدون الطريق لوكالة النموذج التنموي\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.content[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "df.content = [cmt.translate(str.maketrans('', '', string.punctuation)) for cmt in df.content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     یخ علی الخماح مخسر للسیده وجها مازال کتهضرشوهت...\n",
       "1                          یاک مطلقها علاش کیحاسبها داب\n",
       "2     یاخوفي من بدعة التفاخر بالقتل والتشرمیل والمعص...\n",
       "3     يوم يكون الصوت سعره يتحدى 30درهم هنا سيصبح الت...\n",
       "4     يوسف زروالي هو لقتقصدك لدخلو معاه جميعة شباب ا...\n",
       "5                                              يوسف رجل\n",
       "6         يوسف الزروالي هو لي دخلو لي جمعية شباب الملكي\n",
       "7                         يوزع شكون فيق سكيزو من السبات\n",
       "8       يوتيب تسبب ليا بمرض نفسي وليت كنخاف ومرضت نفسيا\n",
       "9     يهدر واش تتوقع منو وجاية ملمريخ نتا واش قودك ي...\n",
       "10                                          يهدر كي نسا\n",
       "11    يهدر بحال النسا سبحان الله يا حبيبتي ه و اليد ...\n",
       "12                                   يه الحاجة طامو يه؟\n",
       "13                                       ينقجو و ينحقزو\n",
       "14    ينعل تحية ليك من طانطان هاد شعب فيهم غا هضرة ت...\n",
       "15            ينعل بو زواج الى كان هكا نبقاو بايرات حسن\n",
       "16                    ينصاب يا لقمار يا سكاير طالب سيدك\n",
       "17                        ينتقم للمستقبل ويريد حكم نزيه\n",
       "18       يمهل ولا يهمل غدي تبان فيك اولدي عقل على كلمتي\n",
       "19                 يمهدون الطريق لوكالة النموذج التنموي\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.content[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models \n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72.38460869565218, 88.66973653460076, 2352)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = df.content.str.len()\n",
    "lens.mean(), lens.std(), lens.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2352\n"
     ]
    }
   ],
   "source": [
    "max_length = df.content.str.len().max()\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Tokens 75033\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "text= df.content\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text)\n",
    "sequences = tokenizer.texts_to_sequences(text)\n",
    "word_index = tokenizer.word_index\n",
    "print('Number of Unique Tokens',len(word_index))\n",
    "\n",
    "#Pad sequences\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_SEQUENCE_LENGTH = 60\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04573694,  0.10975436, -0.54744524,  0.10996349,  0.20633675,\n",
       "        0.90674895,  0.11491557,  0.72445756,  0.58139473, -0.2946483 ,\n",
       "       -0.7712647 , -0.17335273,  0.33888417, -0.20815212,  0.46175632,\n",
       "        0.38756797,  0.28463918, -0.03309639, -0.08293769, -0.13326049,\n",
       "       -0.58587915, -0.48430493, -0.16314602, -0.38404787,  0.08127248,\n",
       "       -0.8705088 ,  0.33157548,  0.3544283 ,  0.5581337 ,  0.08885915,\n",
       "       -1.1427025 ,  0.92506343, -0.09592154,  0.5934387 ,  0.3629863 ,\n",
       "       -0.21132165,  0.30229187,  0.16288331, -0.31264427, -0.04881828,\n",
       "       -0.08142379, -1.4429231 , -0.66444516, -1.4426838 , -1.0821352 ,\n",
       "       -0.05486058,  0.8075012 ,  0.6802713 ,  1.0687793 , -1.7807748 ,\n",
       "       -1.0383372 ,  1.5321866 , -0.8323125 ,  0.3871929 , -0.6774203 ,\n",
       "        1.2722178 ,  0.6946758 , -0.8461339 ,  1.0099423 ,  0.37826127,\n",
       "        0.580605  , -0.18887214, -0.8269939 ,  0.958509  ,  0.4126865 ,\n",
       "       -2.1811097 ,  1.2467979 , -0.53286076, -1.0175996 , -1.9067664 ,\n",
       "        0.28666314,  0.3211824 ,  0.36152586,  0.03873236,  0.11567222,\n",
       "       -0.27572855,  0.40008596, -0.48754787,  0.38737082, -0.28418565,\n",
       "        0.67531437, -1.0435778 ,  0.5332273 ,  0.31403878, -0.16006146,\n",
       "        0.44669232, -0.37455004,  0.64760715,  0.7944252 , -0.1673101 ,\n",
       "        0.31114537,  0.35829428,  0.82467514, -0.09859738,  0.06952368,\n",
       "        0.743998  ,  0.8606476 ,  1.0330786 ,  0.195368  ,  1.466137  ,\n",
       "       -0.6869376 , -1.2886313 ,  0.11665289,  0.15212166,  0.19238776,\n",
       "        0.17601818,  0.08058965,  1.0208833 , -0.03398788, -0.55130786,\n",
       "        0.4621483 , -0.64151394, -0.56264687,  1.7667924 , -0.04481786,\n",
       "        0.29160935,  0.6163913 ,  0.3575182 ,  0.17079593,  0.66659355,\n",
       "        0.7490147 , -0.42043036,  0.33001426,  0.6902049 ,  0.23821431,\n",
       "        0.02644712,  0.38899824, -0.36792997,  0.56095576, -0.98421913,\n",
       "       -0.2874532 ,  0.3757048 , -1.1953392 , -0.05551673, -1.0462332 ,\n",
       "        0.04884027,  0.90418273, -0.9727971 , -1.7145156 , -1.1016665 ,\n",
       "       -0.33412576, -0.722329  ,  0.46915868,  0.3176587 ,  0.24564196,\n",
       "       -0.09449758, -1.0090467 ,  0.4640847 ,  0.24685602, -1.2121451 ,\n",
       "        0.10896289, -0.7096809 ,  0.48300418,  0.82026994,  0.94324416,\n",
       "       -0.28381893,  0.07218458, -0.67454314, -0.10222086,  0.29554874,\n",
       "        0.29396585, -0.8139636 ,  0.39564413,  0.28563786, -0.26136607,\n",
       "       -0.0583098 ,  0.03789631, -0.34128886,  0.7606736 ,  0.14564306,\n",
       "       -0.50173235, -1.1107835 ,  0.87112564,  0.5338736 ,  0.01818668,\n",
       "       -0.58225363, -0.67159975,  0.28691524,  0.7000783 , -0.72561646,\n",
       "       -1.0841587 ,  0.53386396,  0.5334085 , -0.25284845, -0.25336596,\n",
       "       -0.5405159 , -0.17162363,  0.78928316, -0.08952992,  0.20135465,\n",
       "       -0.18344052, -0.32828787, -0.47056177, -0.26173648, -1.1484044 ,\n",
       "       -0.61582357, -0.45826966, -0.24168205,  0.34647277, -0.07735737,\n",
       "        0.17120305,  0.0751796 ,  0.1872714 , -0.23097934, -0.42335337,\n",
       "       -0.10099858, -0.29352722,  0.43377486, -0.27743602, -0.15559284,\n",
       "       -0.3133551 ,  0.22013408, -0.05825771, -0.23800316,  0.14629157,\n",
       "       -0.14093001,  0.0188139 ,  0.74367267, -0.3296734 ,  0.292064  ,\n",
       "        0.9152014 , -0.02085374, -0.23566242, -0.13253464, -0.2467406 ,\n",
       "        0.40335378,  0.38945192, -0.49726966,  0.22120316, -0.37177756,\n",
       "       -0.5032751 , -0.12007734, -0.51552415,  0.03376446, -0.0056019 ,\n",
       "       -0.24845704, -0.14730877,  0.6970639 , -0.8460207 , -0.05524404,\n",
       "        0.35982296, -0.42743808, -0.29602206, -0.02273015, -0.11585757,\n",
       "       -0.50278836,  0.2769604 ,  0.43382564, -0.32675695,  0.6271812 ,\n",
       "       -0.16024353, -0.0462746 , -0.5787718 , -1.1189721 , -0.02874156,\n",
       "        0.95784515, -0.24875918, -0.48838556, -0.04487803, -0.16217646,\n",
       "        1.0770543 ,  1.3823991 , -0.13060248,  0.16246803, -0.91504985,\n",
       "        0.69631225,  0.83266366,  0.04545341,  0.2828461 , -0.47607428,\n",
       "        0.9277611 ,  0.27869776,  0.46836594,  0.12693599,  0.09989545,\n",
       "        0.24356651,  1.0118709 ,  0.17145653,  0.01318971, -0.59942544,\n",
       "        0.09780236, -0.3551247 ,  0.63755554, -0.29126403,  0.41551647,\n",
       "       -0.6987968 , -0.03297559,  0.19081992,  0.41264516, -1.3063927 ,\n",
       "       -0.61155164, -0.21630456,  1.0130134 , -0.49628645, -0.87892354,\n",
       "       -0.1841479 , -0.32971922,  0.38749847, -0.40484345, -0.02286607],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings['علاش']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape dataset\n",
    "import numpy as np\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23000, 60)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 82906 word vectors in MA CBOW model 300d.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('ma_model_cbow_mix.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Total %s word vectors in MA CBOW model 300d.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data Tensor: (75034, 300)\n"
     ]
    }
   ],
   "source": [
    "#Embedding Matrix\n",
    "EMBEDDING_DIM = 300\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "print('Shape of Data Tensor:', embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Input, Embedding, Dropout, Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                    output_dim = embedding_matrix.shape[1],\n",
    "                    input_length=MAX_SEQUENCE_LENGTH,\n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False))\n",
    "model.add(LSTM(128, dropout=0.3, activation='relu', return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(64, dropout=0.3, activation='relu', return_sequences=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                    output_dim = embedding_matrix.shape[1],\n",
    "                    input_length=MAX_SEQUENCE_LENGTH,\n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False))\n",
    "model.add(GRU(128, dropout=0.3, activation='relu', return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(GRU(64, dropout=0.3, activation='relu', return_sequences=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(MAX_SEQUENCE_LENGTH))\n",
    "x = Embedding(input_dim=embedding_matrix.shape[0],\n",
    "              output_dim=embedding_matrix.shape[1],\n",
    "              weights=[embedding_matrix],\n",
    "              input_length = MAX_SEQUENCE_LENGTH,\n",
    "              trainable=False)(inp)\n",
    "x = Bidirectional(LSTM(128, dropout=0.3, activation=\"relu\", return_sequences = True))(x) \n",
    "x = BatchNormalization()(x)\n",
    "x = Bidirectional(LSTM(64, dropout=0.3, activation=\"relu\", return_sequences = False))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(64, activation=\"sigmoid\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-5,\n",
    "    decay_steps=5000,\n",
    "    decay_rate=0.05)\n",
    "#opt = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=opt, \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75034, 300)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "y = df.decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3652, 21400,  1002,  4520,  1925,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [   19,  4087,     2,    26,  2100,     9, 10337, 26427,    47,\n",
       "         1296,    77,    97,  1329, 26428,   241,     2,    14, 26429,\n",
       "         8020,    47,   285,    56,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [  107,    42,     8,    70,     9,   116,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "Name: decision, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Sckaling and Splitting the dataset into training, validation and test sets \"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_sacaled=scaler.fit_transform(X)\n",
    "\n",
    "train_X, temp_X, train_y, temp_y = train_test_split(X_sacaled, y, random_state=50, test_size=0.3)\n",
    "\n",
    "val_X, test_X, val_y, test_y = train_test_split(temp_X, temp_y, random_state=50, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.43347176, -0.47026806, -0.42547837, -0.50554337, -0.05374429,\n",
       "        -0.28953975, -0.41113584, -0.39041364,  1.21574264, -0.35744544,\n",
       "        -0.34400377, -0.32721317, -0.3160984 , -0.29413118, -0.28462509,\n",
       "        -0.27100943, -0.25848987, -0.24458308, -0.23633566, -0.2275233 ,\n",
       "        -0.2177029 , -0.20975404, -0.2047902 , -0.19281332, -0.193013  ,\n",
       "        -0.1826344 , -0.18070872, -0.16945931, -0.16377389, -0.16415078,\n",
       "        -0.15803773, -0.152939  , -0.14494784, -0.14039346, -0.13745062,\n",
       "        -0.12934839, -0.12751047, -0.12323784, -0.12049472, -0.1222893 ,\n",
       "        -0.11633793, -0.11251934, -0.11169008, -0.10915887, -0.10636714,\n",
       "        -0.1043945 , -0.10514416, -0.1055905 , -0.0981657 , -0.09372086,\n",
       "        -0.08994072, -0.09122515, -0.08422031, -0.08920633, -0.08275944,\n",
       "        -0.08287954, -0.08412545, -0.07987521, -0.07776635, -0.0878589 ],\n",
       "       [-0.44940814, -0.51519638, -0.52274184,  0.14756055,  1.97567784,\n",
       "        -0.45580202, -0.41497729, -0.4068492 , -0.38123383, -0.37027583,\n",
       "        -0.34400377, -0.32721317, -0.3160984 , -0.29413118, -0.28462509,\n",
       "        -0.27100943, -0.25848987, -0.24458308, -0.23633566, -0.2275233 ,\n",
       "        -0.2177029 , -0.20975404, -0.2047902 , -0.19281332, -0.193013  ,\n",
       "        -0.1826344 , -0.18070872, -0.16945931, -0.16377389, -0.16415078,\n",
       "        -0.15803773, -0.152939  , -0.14494784, -0.14039346, -0.13745062,\n",
       "        -0.12934839, -0.12751047, -0.12323784, -0.12049472, -0.1222893 ,\n",
       "        -0.11633793, -0.11251934, -0.11169008, -0.10915887, -0.10636714,\n",
       "        -0.1043945 , -0.10514416, -0.1055905 , -0.0981657 , -0.09372086,\n",
       "        -0.08994072, -0.09122515, -0.08422031, -0.08920633, -0.08275944,\n",
       "        -0.08287954, -0.08412545, -0.07987521, -0.07776635, -0.0878589 ],\n",
       "       [-0.44280333, -0.51033493, -0.51254012, -0.50124954, -0.48770381,\n",
       "        -0.45726302, -0.42961138, -0.4068492 , -0.38123383, -0.37027583,\n",
       "        -0.34400377, -0.32721317, -0.3160984 , -0.29413118, -0.28462509,\n",
       "        -0.27100943, -0.25848987, -0.24458308, -0.23633566, -0.2275233 ,\n",
       "        -0.2177029 , -0.20975404, -0.2047902 , -0.19281332, -0.193013  ,\n",
       "        -0.1826344 , -0.18070872, -0.16945931, -0.16377389, -0.16415078,\n",
       "        -0.15803773, -0.152939  , -0.14494784, -0.14039346, -0.13745062,\n",
       "        -0.12934839, -0.12751047, -0.12323784, -0.12049472, -0.1222893 ,\n",
       "        -0.11633793, -0.11251934, -0.11169008, -0.10915887, -0.10636714,\n",
       "        -0.1043945 , -0.10514416, -0.1055905 , -0.0981657 , -0.09372086,\n",
       "        -0.08994072, -0.09122515, -0.08422031, -0.08920633, -0.08275944,\n",
       "        -0.08287954, -0.08412545, -0.07987521, -0.07776635, -0.0878589 ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16100, 60)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16100,)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3450, 60)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3450,)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3450, 60)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3450,)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "504/504 [==============================] - 159s 305ms/step - loss: 0.7365 - acc: 0.4963 - val_loss: 0.7041 - val_acc: 0.4933\n",
      "Epoch 2/5\n",
      "504/504 [==============================] - 154s 306ms/step - loss: 0.7124 - acc: 0.4949 - val_loss: 0.6980 - val_acc: 0.5038\n",
      "Epoch 3/5\n",
      "504/504 [==============================] - 152s 302ms/step - loss: 0.7022 - acc: 0.4977 - val_loss: 0.6994 - val_acc: 0.4977\n",
      "Epoch 4/5\n",
      "504/504 [==============================] - 152s 302ms/step - loss: 0.7011 - acc: 0.5030 - val_loss: 0.6980 - val_acc: 0.4875\n",
      "Epoch 5/5\n",
      "504/504 [==============================] - 152s 302ms/step - loss: 0.7000 - acc: 0.4979 - val_loss: 0.6978 - val_acc: 0.5032\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_y,\n",
    "          epochs=5, \n",
    "          batch_size=32,\n",
    "          validation_data=(val_X, val_y),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting the training and validation loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"b\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"r\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "27/27 [==============================] - 7s 239ms/step - loss: 0.6962 - acc: 0.5035\n",
      "test loss, test acc: [0.6961997747421265, 0.5034782886505127]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(test_X, test_y, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 60) for input KerasTensor(type_spec=TensorSpec(shape=(None, 60), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    }
   ],
   "source": [
    "pred_y=[np.argmax(model.predict(test_X[i]))for i in range(0, len(test_X)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 17,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 43,\n",
       " 41,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 15,\n",
       " 0,\n",
       " 14,\n",
       " 4,\n",
       " 12,\n",
       " 0,\n",
       " 0,\n",
       " 21,\n",
       " 0,\n",
       " 0,\n",
       " 15,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 14,\n",
       " 8,\n",
       " 16,\n",
       " 54,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 14,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 12,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 15,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 22,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 26,\n",
       " 0,\n",
       " 14,\n",
       " 10,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 13,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 35,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 15,\n",
       " 0,\n",
       " 16,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 42,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 15,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 14,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 10,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 11,\n",
       " 0,\n",
       " 5,\n",
       " 12,\n",
       " 7,\n",
       " 11,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 37,\n",
       " 0,\n",
       " 18,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 13,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 23,\n",
       " 23,\n",
       " 6,\n",
       " 11,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 35,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 13,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 19,\n",
       " 12,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 13,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 10,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 15,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 44,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 11,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 19,\n",
       " 0,\n",
       " 11,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 11,\n",
       " 2,\n",
       " 45,\n",
       " 0,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 12,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 14,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 15,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 13,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 21,\n",
       " 0,\n",
       " 14,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 11,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 55,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 12,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 15,\n",
       " 3,\n",
       " 3,\n",
       " 21,\n",
       " 1,\n",
       " 15,\n",
       " 1,\n",
       " 0,\n",
       " 42,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 16,\n",
       " 11,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 12,\n",
       " 15,\n",
       " 14,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 18,\n",
       " 22,\n",
       " 17,\n",
       " 13,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 17,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 18,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 17,\n",
       " 0,\n",
       " 17,\n",
       " 13,\n",
       " 5,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 22,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 13,\n",
       " 13,\n",
       " 0,\n",
       " 41,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 17,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 13,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 17,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 16,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 18,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 11,\n",
       " 25,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 13,\n",
       " 2,\n",
       " 0,\n",
       " 29,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 14,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 17,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 11,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 13,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 12,\n",
       " 0,\n",
       " 45,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 24,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 11,\n",
       " 3,\n",
       " 0,\n",
       " 10,\n",
       " 2,\n",
       " 0,\n",
       " 21,\n",
       " 9,\n",
       " 46,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 25,\n",
       " 0,\n",
       " 2,\n",
       " 11,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 14,\n",
       " 14,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 23,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 13,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 21,\n",
       " 45,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 16,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 10,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 21,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 15,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 16,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 22,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 19,\n",
       " 23,\n",
       " 1,\n",
       " 0,\n",
       " 14,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 24,\n",
       " 3,\n",
       " 11,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 34,\n",
       " 4,\n",
       " 11,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 46,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 15,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 20,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 20,\n",
       " 0,\n",
       " 11,\n",
       " 0,\n",
       " 10,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 12,\n",
       " 32,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 10,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 14,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 20,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 17,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 17,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 15,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 45,\n",
       " 8,\n",
       " 4,\n",
       " 13,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 14,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 15,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 23,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 12,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 38,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 40,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 10,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 43,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 47,\n",
       " 0,\n",
       " 20,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 14,\n",
       " 6,\n",
       " 0,\n",
       " 53,\n",
       " 0,\n",
       " 17,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 34,\n",
       " 9,\n",
       " 0,\n",
       " 26,\n",
       " 9,\n",
       " 18,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 9,\n",
       " 20,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 14,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 38,\n",
       " 6,\n",
       " 0,\n",
       " 23,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 16,\n",
       " 5,\n",
       " 0,\n",
       " 12,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 15,\n",
       " 7,\n",
       " 40,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 17,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 13,\n",
       " 10,\n",
       " 22,\n",
       " 0,\n",
       " 59,\n",
       " 7,\n",
       " 18,\n",
       " ...]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_probs=model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert probs to binary values 0/1\n",
    "pred_y = (pred_y_probs > 0.5).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5029    0.4962    0.4996      1723\n",
      "           1     0.5040    0.5107    0.5073      1727\n",
      "\n",
      "   micro avg     0.5035    0.5035    0.5035      3450\n",
      "   macro avg     0.5035    0.5035    0.5034      3450\n",
      "weighted avg     0.5035    0.5035    0.5035      3450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_y, pred_y, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for 3 samples\n",
      "predictions shape: (3, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions (probabilities -- the output of the last layer) on new data \n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(test_X[:3])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=[]\n",
    "data_test=df.content[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hh 9alak nssalo fih\n",
      "Prediction:  1\n",
      "Real Value:  0\n"
     ]
    }
   ],
   "source": [
    "print(data_test[20050])\n",
    "print(\"Prediction: \" , np.argmax(model.predict(test_X[50])))\n",
    "print(\"Real Value: \", test_y.iloc[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asfi hayawanato lmaghreb\n",
      "Prediction:  [0.5438336  0.5438336  0.5438336  0.5438336  0.44186643 0.5438336\n",
      " 0.5438336  0.5438336  0.5438336  0.5438336  0.5438336  0.5438336\n",
      " 0.5438336  0.5438336  0.5438336  0.5438336  0.5438336  0.5438336\n",
      " 0.5438336  0.5438336  0.5438336  0.5438336  0.5438336  0.5438336\n",
      " 0.5438336  0.5438336  0.5438336  0.5438336  0.5438336  0.5438336\n",
      " 0.5438336  0.5438336  0.5438336  0.5438336  0.5438336  0.5438336\n",
      " 0.5438336  0.5438336  0.5438336  0.5438336  0.5438336  0.5438336\n",
      " 0.5438336  0.5438336  0.5438336  0.5438336  0.5438336  0.5438336\n",
      " 0.5438336  0.5438336  0.5438336  0.5438336  0.5438336  0.5438336\n",
      " 0.5438336  0.5438336  0.5438336  0.5438336  0.5438336  0.5438336 ]\n"
     ]
    }
   ],
   "source": [
    "print(data_test[22000])\n",
    "print(\"Prediction: \" , model.predict(test_X[2000]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(test_y, pred_y)\n",
    "cnf_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
